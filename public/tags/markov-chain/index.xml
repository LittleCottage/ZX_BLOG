<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Markov Chain on Zhanxiong&#39;s Blog</title>
    <link>http://localhost:1313/ZX_BLOG/tags/markov-chain/</link>
    <description>Recent content in Markov Chain on Zhanxiong&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 09 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/ZX_BLOG/tags/markov-chain/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Gaussian Kernel Properties</title>
      <link>http://localhost:1313/ZX_BLOG/posts/2025-06-09-gaussian/</link>
      <pubDate>Mon, 09 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ZX_BLOG/posts/2025-06-09-gaussian/</guid>
      <description>&lt;p&gt;Your question can be reframed as: why the statement (a) $X_t \mid X_{t - 1} \sim N(\sqrt{1 - \beta_t}X_{t - 1}, \beta_t I)$ is equivalent to the statement (b) $X_t$ has the representation $X_t = \sqrt{1 - \beta_t}X_{t - 1} + \sqrt{\beta_t}Z_t$, where $Z_t \sim N(0, I)$ is independent of $X_{t - 1}$?&lt;/p&gt;
&lt;p&gt;While Thomas Lumley has given you a heuristic answer, I agree that you are absolutely entitled to request a more rigorous argument.&lt;/p&gt;
&lt;p&gt;The direction $(b) \Rightarrow (a)$ is an immediate application of the theorem below (Lemma 8.7 in Foundations of Modern Probability (3rd edition) by Olav Kallenberg):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For any random elements $\xi \perp \eta$ in $S, T$ and a measurable function $f: S \times T \to U$, where $S, T, U$ are Borel, define $X = f(\xi, \eta)$. Then $\mathcal{L}(X \mid \xi) = \mathcal{L}\{f(x, \eta)\}|_{x = \xi}$ a.s.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Here &amp;ldquo;$\mathcal{L}(X)$ / $\mathcal{L}(X \mid \xi)$&amp;rdquo; denotes the law (i.e., distribution) of $X$ / conditional law of $X$ given $\xi$. To apply this result, simply let $\xi = X_{t - 1}, \eta = Z_t$, and $X = X_t = \sqrt{1 - \beta_t}X_{t - 1} + \sqrt{\beta_t}Z_t$. If you are interested in the proof to this lemma, check the reference by yourself.&lt;/p&gt;
&lt;p&gt;For the direction $(a) \Rightarrow (b)$, it suffices to prove the conditional distribution of $Z_t := \beta_t^{-1/2}(X_t - \sqrt{1 - \beta_t}X_{t - 1})$ given $X_{t - 1}$ is $N(0, I)$, hence it is independent of $X_{t - 1}$. To this end, we can apply Theorem 8.5(ii) in the same reference (which concerns with the disintegration of the joint distribution of $(X_{t - 1}, X_t)$).  By this theorem, for a Borel set $H \in \mathscr{R}^n$, we have (where the notation $aH + b$ denotes the set ${ax + b: x \in H}$):
$$
\begin{align*}
&amp;amp;\ P(Z_t \in H \mid X_{t - 1}) \\
=&amp;amp;\ P\left(X_t \in \sqrt{\beta_t}H + \sqrt{1 - \beta_t}X_{t - 1} \mid X_{t - 1}\right) \\
=&amp;amp;\ \int_{\sqrt{\beta_t}H + \sqrt{1 - \beta_t}X_{t - 1}}
(2\pi\beta_t)^{-n/2}\exp\left(-\frac{\beta_t^{-n}}{2}(x - \sqrt{1 - \beta_t}X_{t - 1})^\top(x - \sqrt{1 - \beta_t}X_{t - 1})\right)dx \\
=&amp;amp;\ \int_H (2\pi)^{-n/2}\exp\left(-\frac{1}{2}z^\top z\right)dz.
\end{align*}
$$&lt;/p&gt;
&lt;p&gt;where the last step uses the transformation $z = \beta_t^{-n/2}(x - \sqrt{1 - \beta_t}X_{t - 1})$ and the property of the Lebesgue integration. The last expression shows that the conditional distribution of $Z_t$ given $X_{t - 1}$ is exactly $N(0, I)$.  This completes the proof.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
